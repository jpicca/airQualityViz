{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Dependencies & needed API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from time import sleep, time\n",
    "\n",
    "from config import airNowApiKeyShane, airNowApiKeyAudelia, airNowApiKeyCenez, airNowApiKeyJoseph, airNowApiKeyJoey\n",
    "\n",
    "from largest_combined_statistical_areas_v4_t25 import largest_combined_statistical_areas\n",
    "\n",
    "# from daylight_savings_time_dates_v1 import daylight_savings_time_dates\n",
    "from daylight_savings_time_dates_v1_2015_to_2020 import daylight_savings_time_dates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set output data file filepath variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_filepath = \"output_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup counters, empty list to hold data amd API Key Variables to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Counters\n",
    "counterAttempts = 0\n",
    "counterAttemptsPerAPI = 0\n",
    "counterAPI = 1\n",
    "\n",
    "# Setup empty list\n",
    "apiData = []\n",
    "\n",
    "# Setup API Key Variables\n",
    "airNowApiKey1 = airNowApiKeyShane\n",
    "airNowApiKey2 = airNowApiKeyAudelia\n",
    "airNowApiKey3 = airNowApiKeyCenez\n",
    "airNowApiKey4 = airNowApiKeyJoseph\n",
    "airNowApiKey5 = airNowApiKeyJoey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a list of date ranges to iterate through (due to API limitations, list for each month: [monthStartDate, monthEndDate] -or- quarter [quarterStartDate, quarterEndDate]; January 2015 to April 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Set Date Range to use for API\n",
    "# # startDate = \"2015-01-01\"\n",
    "# startDate = \"2019-12-01\" # Used for testing\n",
    "# # endDate = \"2020-04-30\"\n",
    "# endDate = \"2019-12-31\" # Used for testing\n",
    "\n",
    "# # Create empty list to start\n",
    "# datesToUseList = []\n",
    "# monthStartDateList = pd.date_range(startDate,endDate, freq = '1M') - pd.offsets.MonthBegin(1)\n",
    "# monthEndDateList = pd.date_range(startDate,endDate, freq = '1M')\n",
    "\n",
    "# for date in monthEndDateList:\n",
    "#     datesToUseList.append([(date - pd.offsets.MonthBegin(1)).strftime(\"%Y-%m-%d\"), date.strftime(\"%Y-%m-%d\")])\n",
    "\n",
    "# Create list of Q ranges for each year of data we need\n",
    "datesToUseList = [\n",
    "    ['2015-01-01', '2015-03-31'],\n",
    "    ['2015-04-01', '2015-06-30'],\n",
    "    ['2015-07-01', '2015-09-30'],\n",
    "    ['2015-10-01', '2015-12-31'],\n",
    "    ['2016-01-01', '2016-03-31'],\n",
    "    ['2016-04-01', '2016-06-30'],\n",
    "    ['2016-07-01', '2016-09-30'],\n",
    "    ['2016-10-01', '2016-12-31'],\n",
    "    ['2017-01-01', '2017-03-31'],\n",
    "    ['2017-04-01', '2017-06-30'],\n",
    "    ['2017-07-01', '2017-09-30'],\n",
    "    ['2017-10-01', '2017-12-31'],\n",
    "    ['2018-01-01', '2018-03-31'],\n",
    "    ['2018-04-01', '2018-06-30'],\n",
    "    ['2018-07-01', '2018-09-30'],\n",
    "    ['2018-10-01', '2018-12-31'],\n",
    "    ['2019-01-01', '2019-03-31'],\n",
    "    ['2019-04-01', '2019-06-30'],\n",
    "    ['2019-07-01', '2019-09-30'],\n",
    "    ['2019-10-01', '2019-12-31'],\n",
    "    ['2020-01-01', '2020-03-31'],\n",
    "    ['2020-04-01', '2020-06-30']\n",
    "]\n",
    "\n",
    "\n",
    "# datesToUseList\n",
    "len(datesToUseList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a list of date that are within the Daylight Savings Time period to determine which UTC Offset to use for each city (January 2015 to Dec  2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1434"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a date list of DST dates\n",
    "dstDateList = []\n",
    "for year in daylight_savings_time_dates:\n",
    "    dstStart = year[\"dates\"][\"start\"]\n",
    "    dstEnd = year[\"dates\"][\"end\"]\n",
    "    dstDateListHolder = pd.date_range(dstStart, dstEnd).strftime(\"%Y-%m-%d\").tolist()\n",
    "    for date in dstDateListHolder:\n",
    "        dstDateList.append(date)\n",
    "\n",
    "# dstDateList\n",
    "len(dstDateList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup API Call Function and with URL, API Key, and variables to pass through in the requests.get() API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apiAirNowObsByMonitoringSite(csaRank, csaName, csaPrimaryCity, csaPrimaryCityState, csaPopulation2018Estimate, csaPopulation2010Census, csaPrimaryCityLat, csaPrimaryCityLong, csaPrimaryCityZip, csaTimeZone, csaStandardTimeUtcOffset, csaDaylightSavingsTimeUtcOffset, csaMonitoringStationLat, csaMonitoringStationLong, csaSearchRadius, csaBboxVar, obsStartDate, obsStartHour, obsEndDate, ObsEndHour, apiKey, apiKeyUsed, counterAttempts, counterAttemptsPerAPI, counterAPI):\n",
    "    # Empty response list variable every time function is called\n",
    "    response = []\n",
    "    \n",
    "    # Set variables to pass through to API parameters\n",
    "#     particulates = \"ozone,pm25,pm10,co,no2,so2\"\n",
    "    particulates = \"ozone,pm25,pm10\"\n",
    "    longMin = round(csaMonitoringStationLong - csaBboxVar,3)\n",
    "    longMax = round(csaMonitoringStationLong + csaBboxVar,3)\n",
    "    latMin = round(csaMonitoringStationLat - csaBboxVar,3)\n",
    "    latMax = round(csaMonitoringStationLat + csaBboxVar,3)\n",
    "    \n",
    "    # Set API Parameters to be passed through to API requests.get\n",
    "    params = {}\n",
    "    params[\"baseURL\"] = \"http://www.airnowapi.org/aq/data/\"\n",
    "    params[\"obsStartDate\"] = f\"{obsStartDate}\"\n",
    "    params[\"obsStartHour\"] = f\"{obsStartHour}\"\n",
    "    params[\"obsEndDate\"] = f\"{obsEndDate}\"\n",
    "    params[\"obsEndHour\"] = f\"{obsEndHour}\"\n",
    "    params[\"particulates\"] = f\"{particulates}\"\n",
    "    params[\"bbox\"] = f\"{longMin},{latMin},{longMax},{latMax}\"\n",
    "    params[\"dataType\"] = \"A\" # A = AQI (C = Concentrations; B = AQI & Concentrations)\n",
    "    params[\"format\"] = \"application/json\"\n",
    "    params[\"verbose\"] = \"1\" # 1 = True; provides additional site information including Site Name, Agency Name, AQS ID, and Full AQS ID (0 = False)\n",
    "    params[\"nowCastOnly\"] = \"0\" # 0 = False; concentrations and AQI will transition to midpoint averages as data becomes available (1 = True; always provides Nowcast concentrations and AQI regardless of date/time)\n",
    "    params[\"includeRawConcentrations\"] = \"0\" # 0 = False (1 = True; an additional field that contains the raw concentration will be added to the output. For CO, NO2, and SO2, these values are the same as the concentration fields. For Ozone, PM2.5, and PM10, these are raw hourly concentrations measured by the instrument (Not Nowcast or Midpoint avg. concentrations) Raw concentration units are the same as those specified in the Unit field)\n",
    "    params[\"apiKey\"] = apiKey\n",
    "    \n",
    "    # Build API Request URL, passing through parameters - by GEOGRAPHIC BOUNDING BOX\n",
    "    requestURL = params[\"baseURL\"] \\\n",
    "                + \"?startDate=\" + params[\"obsStartDate\"] + \"T\" + params[\"obsStartHour\"] \\\n",
    "                + \"&endDate=\" + params[\"obsEndDate\"] + \"T\" + params[\"obsEndHour\"] \\\n",
    "                + \"&parameters=\" + params[\"particulates\"] \\\n",
    "                + \"&BBOX=\" + params[\"bbox\"] \\\n",
    "                + \"&dataType=\" + params[\"dataType\"] \\\n",
    "                + \"&format=\" + params[\"format\"] \\\n",
    "                + \"&verbose=\" + params[\"verbose\"] \\\n",
    "                + \"&nowcastonly=\" + params[\"nowCastOnly\"] \\\n",
    "                + \"&includerawconcentrations=\" + params[\"includeRawConcentrations\"] \\\n",
    "                + \"&API_KEY=\" + params[\"apiKey\"]\n",
    "    \n",
    "    # Logger: Print status message\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Requesting AirNow API Data for...\")\n",
    "    print(\"     **************************************************\")\n",
    "    print(datetime.now().strftime('%Y-%m-%d.%H.%M.%S'))\n",
    "    print(f\"CSA: {csaName} | CITY: {csaPrimaryCity}, {csaPrimaryCityState} | minLatLong: [{latMin},{longMin}] | maxLatLong: [{latMax},{longMax}] | DATE RANGE: {obsStartDate} - {obsEndDate}\")\n",
    "    print(f\"ATTEMPT:{counterAttempts} | ATTEMPT PER BATCH/API: {counterAttemptsPerAPI} | BATCH/API: {counterAPI} | API Key Used: {apiKeyUsed}\")\n",
    "    print(\"     **************************************************\")\n",
    "    \n",
    "    # Set up error handling in the even there is an error in the API requests.get()\n",
    "    try:\n",
    "        \n",
    "        # Execute requests.get, passing through built requestURL\n",
    "        response = requests.get(requestURL).json()\n",
    "        responseCode = requests.get(requestURL)\n",
    "        \n",
    "        # Results sum and response Code:\n",
    "        print(\"     **************************************************\")\n",
    "        print(f\"Number of results found: {len(response)}\")\n",
    "        print(f\"Response Code: {responseCode}\")\n",
    "        print(\"     **************************************************\")\n",
    "\n",
    "        # Loop through response, appending each element (dictionary) as a new item in the apiData list\n",
    "        for i in range(len(response)):\n",
    "            \n",
    "            # Add values brought in from the largest_combined_statistical_areas dictionary / json object to the response\n",
    "            response[i][\"csaRank\"] = csaRank\n",
    "            response[i][\"csaName\"] = csaName\n",
    "            response[i][\"csaPrimaryCity\"] = csaPrimaryCity\n",
    "            response[i][\"csaPrimaryCityState\"] = csaPrimaryCityState\n",
    "            response[i][\"csaPopulation2018Estimate\"] = csaPopulation2018Estimate\n",
    "            response[i][\"csaPopulation2010Census\"] = csaPopulation2010Census\n",
    "            response[i][\"csaPrimaryCityLat\"] = csaPrimaryCityLat\n",
    "            response[i][\"csaPrimaryCityLong\"] = csaPrimaryCityLong\n",
    "            response[i][\"csaPrimaryCityZip\"] = csaPrimaryCityZip\n",
    "          \n",
    "            response[i][\"csaTimeZone\"] = csaTimeZone\n",
    "            response[i][\"csaStandardTimeUtcOffset\"] = csaStandardTimeUtcOffset\n",
    "            response[i][\"csaDaylightSavingsTimeUtcOffset\"] = csaDaylightSavingsTimeUtcOffset\n",
    "            response[i][\"csaMonitoringStationLat\"] = csaMonitoringStationLat\n",
    "            response[i][\"csaMonitoringStationLong\"] = csaMonitoringStationLong\n",
    "            response[i][\"csaSearchRadius\"] = csaSearchRadius\n",
    "            response[i][\"csaBboxVar\"] = csaBboxVar            \n",
    "            \n",
    "            # Append the response to the apiData list\n",
    "            apiData.append(response[i])\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"     **************************************************\")\n",
    "        print(f\"Response Code: {responseCode}\")\n",
    "        print(\"     **************************************************\")\n",
    "        print(f\"ERROR: Unable to perform AirNow API request for CSA: {csaName} | CITY: {csaPrimaryCity}, {csaPrimaryCityState} | minLatLong: [{latMin},{longMin}] | maxLatLong: [{latMax},{longMax}] | DATE RANGE: {obsStartDate} - {obsEndDate}\")\n",
    "        print(\"%s\" % e)\n",
    "        print(\"--------------------------------------------------\")\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop through cities and dates, while updating variables and passing them through to the apiAirNowObsByMonitoringSite Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Requesting AirNow API Data for...\n",
      "     **************************************************\n",
      "2020-04-17.02.18.01\n",
      "CSA: New York-Newark, NY-NJ-CT-PA Combined Statistical Area | CITY: New York City, NY | minLatLong: [40.692,-73.986] | maxLatLong: [40.992,-73.686] | DATE RANGE: 2015-01-01 - 2015-03-31\n",
      "ATTEMPT:1 | ATTEMPT PER BATCH/API: 1 | BATCH/API: 1 | API Key Used: airNowApiKey1\n",
      "     **************************************************\n",
      "     **************************************************\n",
      "Number of results found: 22488\n",
      "Response Code: <Response [200]>\n",
      "     **************************************************\n",
      "--------------------------------------------------\n",
      "Requesting AirNow API Data for...\n",
      "     **************************************************\n",
      "2020-04-17.02.19.23\n",
      "CSA: New York-Newark, NY-NJ-CT-PA Combined Statistical Area | CITY: New York City, NY | minLatLong: [40.692,-73.986] | maxLatLong: [40.992,-73.686] | DATE RANGE: 2015-04-01 - 2015-06-30\n",
      "ATTEMPT:2 | ATTEMPT PER BATCH/API: 2 | BATCH/API: 1 | API Key Used: airNowApiKey1\n",
      "     **************************************************\n",
      "     **************************************************\n",
      "Number of results found: 25893\n",
      "Response Code: <Response [200]>\n",
      "     **************************************************\n",
      "--------------------------------------------------\n",
      "Requesting AirNow API Data for...\n",
      "     **************************************************\n",
      "2020-04-17.02.21.01\n",
      "CSA: New York-Newark, NY-NJ-CT-PA Combined Statistical Area | CITY: New York City, NY | minLatLong: [40.692,-73.986] | maxLatLong: [40.992,-73.686] | DATE RANGE: 2015-07-01 - 2015-09-30\n",
      "ATTEMPT:3 | ATTEMPT PER BATCH/API: 3 | BATCH/API: 1 | API Key Used: airNowApiKey1\n",
      "     **************************************************\n",
      "     **************************************************\n",
      "Number of results found: 26023\n",
      "Response Code: <Response [200]>\n",
      "     **************************************************\n",
      "--------------------------------------------------\n",
      "Requesting AirNow API Data for...\n",
      "     **************************************************\n",
      "2020-04-17.02.22.37\n",
      "CSA: New York-Newark, NY-NJ-CT-PA Combined Statistical Area | CITY: New York City, NY | minLatLong: [40.692,-73.986] | maxLatLong: [40.992,-73.686] | DATE RANGE: 2015-10-01 - 2015-12-31\n",
      "ATTEMPT:4 | ATTEMPT PER BATCH/API: 4 | BATCH/API: 1 | API Key Used: airNowApiKey1\n",
      "     **************************************************\n",
      "     **************************************************\n",
      "Number of results found: 26301\n",
      "Response Code: <Response [200]>\n",
      "     **************************************************\n",
      "--------------------------------------------------\n",
      "Requesting AirNow API Data for...\n",
      "     **************************************************\n",
      "2020-04-17.02.24.12\n",
      "CSA: New York-Newark, NY-NJ-CT-PA Combined Statistical Area | CITY: New York City, NY | minLatLong: [40.692,-73.986] | maxLatLong: [40.992,-73.686] | DATE RANGE: 2016-01-01 - 2016-03-31\n",
      "ATTEMPT:5 | ATTEMPT PER BATCH/API: 5 | BATCH/API: 1 | API Key Used: airNowApiKey1\n",
      "     **************************************************\n"
     ]
    }
   ],
   "source": [
    "# Loop through cities in the largest_combined_statistical_areas dictionary / json object\n",
    "for csa in largest_combined_statistical_areas:\n",
    "    \n",
    "    # Loop through datesToUseList, calling the apiAirNowObsByMonitoringSite function, passing through variables\n",
    "    for date in datesToUseList:\n",
    "    \n",
    "        # Set varaiable values to pass into the apiAirNowObsByMonitoringSite function\n",
    "        csaRank = csa[\"csa_rank\"]\n",
    "        csaName = csa[\"csa_name\"]\n",
    "        csaPrimaryCity = csa[\"primary_city\"]\n",
    "        csaPrimaryCityState = csa[\"primary_city_state\"]\n",
    "        csaPopulation2018Estimate = csa[\"population\"][\"2018_estimate\"]\n",
    "        csaPopulation2010Census = csa[\"population\"][\"2010_census\"]\n",
    "        csaPrimaryCityLat = csa[\"primary_city_location\"][\"lat\"]\n",
    "        csaPrimaryCityLong = csa[\"primary_city_location\"][\"long\"]\n",
    "        csaPrimaryCityZip = csa[\"primary_city_location\"][\"zip_code\"]\n",
    "        csaTimeZone = csa[\"timezone_params\"][\"timezone\"]\n",
    "        csaStandardTimeUtcOffset = csa[\"timezone_params\"][\"utc_offset\"][\"standard_time\"]\n",
    "        csaDaylightSavingsTimeUtcOffset = csa[\"timezone_params\"][\"utc_offset\"][\"daylight_savings_time\"]\n",
    "        csaMonitoringStationLat = csa[\"search_params\"][\"closest_monitoring_station\"][\"lat\"]\n",
    "        csaMonitoringStationLong = csa[\"search_params\"][\"closest_monitoring_station\"][\"long\"]\n",
    "        csaSearchRadius = csa[\"search_params\"][\"closest_monitoring_station\"][\"search_radius\"]\n",
    "        csaBboxVar = csa[\"search_params\"][\"closest_monitoring_station\"][\"bbox_latlong_var\"]\n",
    "        \n",
    "        obsStartDate = date[0]\n",
    "        obsStartHour = \"00\"\n",
    "        obsEndDate = date[1]\n",
    "        obsEndHour = \"23\"\n",
    "                \n",
    "        # Update overall attempt counter\n",
    "        counterAttempts += 1\n",
    "        \n",
    "        # Once 250 attempts have been made for all five API Keys, reset counterAttemptsPerAPI, counterAPI and apiKey then sleep for one hour (3600 seconds)\n",
    "        if counterAttemptsPerAPI >= 250 and counterAPI >= 5:\n",
    "            counterAttemptsPerAPI = 1\n",
    "            counterAPI = 1\n",
    "            apiKey = airNowApiKey1\n",
    "            print(\"*****  250 per API for all APIs avialable reached | RESET counterAttemptsPerAPI, counterAPI, apiKey & SLEEP  *****\")\n",
    "            sleep(3)\n",
    "\n",
    "        # Once 250 attempts have been made for the currently used API Key, update counterAPI so a new apiKey is used next time through, reset counterAttemptsPerAPI\n",
    "        elif counterAttemptsPerAPI >= 250:\n",
    "            counterAPI += 1\n",
    "            counterAttemptsPerAPI = 1\n",
    "            print(\"*****  250 per current API reached | RESET counterAttemptsPerAPI; UPDATE counterAPI & apiKey  *****\")\n",
    "            \n",
    "        else:\n",
    "            counterAttemptsPerAPI += 1\n",
    "\n",
    "        # Set apiKey variable based on the counterAPI variable\n",
    "        if counterAPI == 1:\n",
    "            apiKey = airNowApiKey1\n",
    "            apiKeyUsed = \"airNowApiKey1\"\n",
    "        elif counterAPI == 2:\n",
    "            apiKey = airNowApiKey2\n",
    "            apiKeyUsed = \"airNowApiKey2\"\n",
    "        elif counterAPI == 3:\n",
    "            apiKey = airNowApiKey3\n",
    "            apiKeyUsed = \"airNowApiKey3\"\n",
    "        elif counterAPI == 4:\n",
    "            apiKey = airNowApiKey4\n",
    "            apiKeyUsed = \"airNowApiKey4\"\n",
    "        elif counterAPI == 5:\n",
    "            apiKey = airNowApiKey5\n",
    "            apiKeyUsed = \"airNowApiKey5\"\n",
    "        \n",
    "        # Call the apiCallLatLongHistorical function, passing through updated variables as parameters\n",
    "        apiAirNowObsByMonitoringSite(csaRank, csaName, csaPrimaryCity, csaPrimaryCityState, csaPopulation2018Estimate, csaPopulation2010Census, csaPrimaryCityLat, csaPrimaryCityLong, csaPrimaryCityZip, csaTimeZone, csaStandardTimeUtcOffset, csaDaylightSavingsTimeUtcOffset, csaMonitoringStationLat, csaMonitoringStationLong, csaSearchRadius, csaBboxVar, obsStartDate, obsStartHour, obsEndDate, obsEndHour, apiKey, apiKeyUsed, counterAttempts, counterAttemptsPerAPI, counterAPI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the number of records in the apiData list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apiData\n",
    "len(apiData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop through results and only use the records that are for a chosen datetime (noon local time for each city, checking to see if date is within Standard Time (ST) or Daylight Savings Time (DST) periods and then use the correct UTC offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set an empty list to hold the data being passed through\n",
    "selectedDateTimeApiData = []\n",
    "\n",
    "# Loop through the apiData\n",
    "for record in apiData:\n",
    "    \n",
    "    # Set variables and calculate desired local datetime for the record we want to use (12:00 noon, local time per each city)\n",
    "    desiredLocalTime = \"12:00\"\n",
    "    \n",
    "    # Isolate just the date of the \"UTC\" datetime stamp string\n",
    "    recordDate = pd.Timestamp(record[\"UTC\"]).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Create variable for the city's local datetime we want to use\n",
    "    desiredLocalDateTime = pd.Timestamp(f\"{recordDate}T{desiredLocalTime}\")\n",
    "\n",
    "    # Create Standard Time variables to use\n",
    "    stdTimeOffsetInt = int(record[\"csaStandardTimeUtcOffset\"].replace(\"0\",\"\").replace(\":\",\"\"))\n",
    "    stdDesiredUTCDateTime = desiredLocalDateTime + timedelta(hours = (stdTimeOffsetInt * -1))\n",
    "    stdDesiredUTCDateTimeStr = stdDesiredUTCDateTime.strftime(\"%Y-%m-%dT%H%:%M\")\n",
    "    \n",
    "    # Create Daylight Savings Time variables to use\n",
    "    dstTimeOffsetInt = int(record[\"csaDaylightSavingsTimeUtcOffset\"].replace(\"0\",\"\").replace(\":\",\"\"))\n",
    "    dstDesiredUTCDateTime = desiredLocalDateTime + timedelta(hours = (dstTimeOffsetInt * -1))\n",
    "    dstDesiredUTCDateTimeStr = dstDesiredUTCDateTime.strftime(\"%Y-%m-%dT%H%:%M\")\n",
    "    \n",
    "    # If the record date is within a DST period and the \"UTC\" datetime stamp matches desired for DST\n",
    "    if recordDate in dstDateList and record[\"UTC\"] == dstDesiredUTCDateTimeStr:\n",
    "        \n",
    "        # Append the response to the apiData list\n",
    "        record[\"st_dst\"] = \"DaylightSavings\"\n",
    "        record[\"obsDateTime\"] = desiredLocalDateTime.strftime(\"%Y-%m-%dT%H%:%M\")\n",
    "        record[\"dateObserved\"] = desiredLocalDateTime.strftime(\"%Y-%m-%d\")\n",
    "        record[\"timeObserved\"] = desiredLocalDateTime.strftime(\"%H%:%M\")\n",
    "        selectedDateTimeApiData.append(record)\n",
    "        \n",
    "    # If the record date is within a ST period and the \"UTC\" datetime stamp matches desired for ST\n",
    "    elif recordDate not in dstDateList and record[\"UTC\"] == stdDesiredUTCDateTimeStr:\n",
    "        \n",
    "        # Append the response to the apiData list\n",
    "        record[\"st_dst\"] = \"Standard\"\n",
    "        record[\"obsDateTime\"] = desiredLocalDateTime.strftime(\"%Y-%m-%dT%H%:%M\")\n",
    "        record[\"dateObserved\"] = desiredLocalDateTime.strftime(\"%Y-%m-%d\")\n",
    "        record[\"timeObserved\"] = desiredLocalDateTime.strftime(\"%H%:%M\")\n",
    "        selectedDateTimeApiData.append(record)\n",
    "        \n",
    "    else:\n",
    "        # Ignore the record, do not pass to selectedDateTimeApiData\n",
    "        pass\n",
    "\n",
    "# See how many records/result are included\n",
    "# selectedDateTimeApiData\n",
    "len(selectedDateTimeApiData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create DataFrame holding the values from the selectedDateTimeApiData lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selectedDateTimeApiData_df = pd.DataFrame(selectedDateTimeApiData)\n",
    "\n",
    "# Visualize the DataFrame\n",
    "selectedDateTimeApiData_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert & export raw DataFrame to CSV files (in the event we need to update/manipulate later from this point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "selectedDateTimeApiData_df.to_csv(f\"{output_data_filepath}AirNowApiRawData_{timestamp}.csv\", encoding=\"utf-8\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedApiData_df = selectedDateTimeApiData_df\n",
    "\n",
    "# Visualize the DataFrame\n",
    "cleanedApiData_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop reporting results that have Category of 0 (AQI = -999; null/bad values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedApiData_df = cleanedApiData_df[cleanedApiData_df.Category != 0]\n",
    "# cleanedApiData_df = cleanedApiData_df[cleanedApiData_df.Category != -999]\n",
    "\n",
    "# Visualize the DataFrame\n",
    "cleanedApiData_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what Columns are included and how they are named\n",
    "list(cleanedApiData_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename Columns (for relevancy downstream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedApiData_df = cleanedApiData_df.rename(columns={\"Latitude\": \"SiteLatitude\",\\\n",
    "                                                      \"Longitude\": \"SiteLongitude\",\\\n",
    "                                                      \"UTC\": \"DateTimeObservedUTC\",\\\n",
    "                                                      \"Parameter\": \"ParameterName\",\\\n",
    "                                                      \"Category\": \"AQICategoryNumber\",\\\n",
    "                                                      \"AgencyName\": \"SiteAgencyName\",\\\n",
    "                                                      \"FullAQSCode\": \"SiteAQSCode\",\\\n",
    "                                                      \"IntlAQSCode\": \"SiteIntlAQSCode\",\\\n",
    "                                                      \"st_dst\": \"TimeMode\",\\\n",
    "                                                      \"obsDateTime\": \"DateTimeObserved\",\\\n",
    "                                                      \"dateObserved\": \"DateObserved\",\\\n",
    "                                                      \"timeObserved\": \"TimeObserved\"})\n",
    "\n",
    "# Visualize the updated DataFrame\n",
    "cleanedApiData_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add AQICategory (Good, Moderate, Unhealthy for Sensitive Groups, Unhealthy, Very Unhealthy; based on AQICategoryNumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to determine AQICategory value based on AQICategoryNumber\n",
    "def fAQICategory(row):\n",
    "    if row[\"AQICategoryNumber\"] == 1:\n",
    "        AQICategory = \"Good\"\n",
    "    elif row[\"AQICategoryNumber\"] == 2:\n",
    "        AQICategory = \"Moderate\"\n",
    "    elif row[\"AQICategoryNumber\"] == 3:\n",
    "        AQICategory = \"Unhealthy for Sensitive Groups\"\n",
    "    elif row[\"AQICategoryNumber\"] == 4:\n",
    "        AQICategory = \"Unhealthy\"\n",
    "    elif row[\"AQICategoryNumber\"] == 5:\n",
    "        AQICategory = \"Very Unhealthy\"\n",
    "    elif row[\"AQICategoryNumber\"] == 6:\n",
    "        AQICategory = \"Hazardous\"\n",
    "    else:\n",
    "        AQICategory = \"(invalid)\"\n",
    "    return AQICategory\n",
    "\n",
    "# Create new column: AQICategory, using above function\n",
    "cleanedApiData_df['AQICategory'] = cleanedApiData_df.apply(fAQICategory, axis=1)\n",
    "\n",
    "# Visualize the DataFrame\n",
    "cleanedApiData_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what Columns are included and how they are named\n",
    "list(cleanedApiData_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop unneeded columns | Reorder columns (for efficiency downstream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedApiData_df = cleanedApiData_df[[\"csaRank\", \"csaName\", \"csaPrimaryCity\", \"csaPrimaryCityState\",\\\n",
    "                                       \"csaPrimaryCityLat\", \"csaPrimaryCityLong\", \"csaTimeZone\", \"TimeMode\",\\\n",
    "                                       \"DateTimeObserved\", \"DateObserved\", \"TimeObserved\", \"DateTimeObservedUTC\",\\\n",
    "                                       \"ParameterName\", \"Unit\", \"AQI\", \"AQICategoryNumber\", \"AQICategory\",\\\n",
    "                                       \"SiteName\", \"SiteAgencyName\"]]\n",
    "\n",
    "# Visualize the updated DataFrame\n",
    "cleanedApiData_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert & export cleaned DataFrame to CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "cleanedApiData_df.to_csv(f\"{output_data_filepath}AirNowApiData_{timestamp}.csv\", encoding=\"utf-8\", index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See the column names we are working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(cleanedApiData_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Grouped DataFrame (that groups all columns except values that are aggregated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedApiData_df = cleanedApiData_df.groupby([\"csaRank\", \"csaName\", \"csaPrimaryCity\", \"csaPrimaryCityState\",\\\n",
    "                                               \"csaPrimaryCityLat\", \"csaPrimaryCityLong\", \"csaTimeZone\",\\\n",
    "                                               \"TimeMode\", \"DateTimeObserved\", \"DateObserved\", \"TimeObserved\",\\\n",
    "                                               \"DateTimeObservedUTC\", \"ParameterName\", \"Unit\"\n",
    "                                              ])\n",
    "\n",
    "# Visualize the DataFrame (use .count() to see it)\n",
    "groupedApiData_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate values (aqiCount, aqiAvg, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the count of AQI readings\n",
    "aqiCount = groupedApiData_df[\"AQI\"].count()\n",
    "# aqiCount\n",
    "\n",
    "# Calculate the avg (mean) AQI\n",
    "aqiAvg = groupedApiData_df[\"AQI\"].mean()\n",
    "# aqiAvg\n",
    "\n",
    "# Calculate the min AQI\n",
    "aqiMin = groupedApiData_df[\"AQI\"].min()\n",
    "# aqiMin\n",
    "\n",
    "# Calculate the min AQI\n",
    "aqiMax = groupedApiData_df[\"AQI\"].max()\n",
    "# aqiMax\n",
    "\n",
    "# Calculate the avg (mean) AQI Category Number\n",
    "aqiCategoryNumberAvg = groupedApiData_df[\"AQICategoryNumber\"].mean()\n",
    "# aqiCategoryAvg\n",
    "\n",
    "# Calculate the min AQI Category Number\n",
    "aqiCategoryNumberMin = groupedApiData_df[\"AQICategoryNumber\"].min()\n",
    "# aqiCategoryMin\n",
    "\n",
    "# Calculate the min AQI Category Number\n",
    "aqiCategoryNumberMax = groupedApiData_df[\"AQICategoryNumber\"].max()\n",
    "# aqiCategoryMax\n",
    "\n",
    "# Calculate the number of unique AQI Categories\n",
    "aqiCategoryCount = groupedApiData_df[\"AQICategory\"].nunique()\n",
    "\n",
    "# Calculate the number of unique sites\n",
    "sitesCount = groupedApiData_df[\"SiteName\"].nunique()\n",
    "# sitesTotal\n",
    "\n",
    "# Calculate the number of unique agencies\n",
    "agenciesCount = groupedApiData_df[\"SiteAgencyName\"].nunique()\n",
    "# agenciesTotal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Summary DataFrame (that holds the grouped and aggregated values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaryApiData_df = pd.DataFrame({\"aqiCount\": aqiCount,\n",
    "                                  \"aqiAvg\": aqiAvg,\n",
    "                                  \"aqiMin\": aqiMin,\n",
    "                                  \"aqiMax\": aqiMax,\n",
    "                                  \"aqiCategoryNumberAvg\": aqiCategoryNumberAvg,\n",
    "                                  \"aqiCategoryNumberMin\": aqiCategoryNumberMin,\n",
    "                                  \"aqiCategoryNumberMax\": aqiCategoryNumberMax,\n",
    "                                  \"aqiCategoryCount\": aqiCategoryCount,\n",
    "                                  \"sitesCount\": sitesCount,\n",
    "                                  \"agenciesCount\": agenciesCount\n",
    "                                 })\n",
    "\n",
    "# Reset index for the DataFrame\n",
    "summaryApiData_df = summaryApiData_df.reset_index()\n",
    "\n",
    "# Sort DataFrame by CSA, Parameter and DateObserved\n",
    "summaryApiData_df = summaryApiData_df.sort_values([\"csaRank\",\"ParameterName\",\"DateObserved\"], ascending=[True,True,True])\n",
    "\n",
    "# Reset Index\n",
    "summaryApiData_df = summaryApiData_df.reset_index()\n",
    "del summaryApiData_df[\"index\"]\n",
    "\n",
    "# Visualize the DataFrame\n",
    "summaryApiData_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add AQICategoryNumber & AQICategory (1 = Good, 2 = Moderate, 3 = Unhealthy for Sensitive Groups, 4 = Unhealthy, 5 = Very Unhealthy, 6 = Hazardous; based on aqiAvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column: AQICategory, using above function\n",
    "summaryApiData_df['AQICategory'] = summaryApiData_df.apply(faqiAvgAQICategory, axis=1)\n",
    "\n",
    "# Create function to determine AQICategoryNumber value based on aqiAvg\n",
    "def faqiAvgAQICategoryNumber(row):\n",
    "    if round(row[\"aqiAvg\"],0) >= 0 and round(row[\"aqiAvg\"],0) < 51:\n",
    "        AQICategoryNumber = 1\n",
    "        AQICategory = \"Good\"\n",
    "    elif round(row[\"aqiAvg\"],0) >= 51 and round(row[\"aqiAvg\"],0) < 101:\n",
    "        AQICategoryNumber = 2\n",
    "        AQICategory = \"Moderate\"\n",
    "    elif round(row[\"aqiAvg\"],0) >= 101 and round(row[\"aqiAvg\"],0) < 151:\n",
    "        AQICategoryNumber = 3\n",
    "        AQICategory = \"Unhealthy for Sensitive Groups\"\n",
    "    elif round(row[\"aqiAvg\"],0) >= 151 and round(row[\"aqiAvg\"],0) < 201:\n",
    "        AQICategoryNumber = 4\n",
    "        AQICategory = \"Unhealthy\"\n",
    "    elif round(row[\"aqiAvg\"],0) >= 201 and round(row[\"aqiAvg\"],0) < 301:\n",
    "        AQICategoryNumber = 5\n",
    "        AQICategory = \"Very Unhealthy\"\n",
    "    elif round(row[\"aqiAvg\"],0) >= 301:\n",
    "        AQICategoryNumber = 6\n",
    "        AQICategory = \"Hazardous\"\n",
    "    return AQICategoryNumber\n",
    "\n",
    "# Create new column: AQICategoryNumber, using above function\n",
    "summaryApiData_df['AQICategoryNumber'] = summaryApiData_df.apply(faqiAvgAQICategoryNumber, axis=1)# Create function to determine AQICategory value based on aqiAvg\n",
    "def faqiAvgAQICategory(row):\n",
    "    if round(row[\"aqiAvg\"],0) >= 0 and round(row[\"aqiAvg\"],0) < 51:\n",
    "        AQICategoryNumber = 1\n",
    "        AQICategory = \"Good\"\n",
    "    elif round(row[\"aqiAvg\"],0) >= 51 and round(row[\"aqiAvg\"],0) < 101:\n",
    "        AQICategoryNumber = 2\n",
    "        AQICategory = \"Moderate\"\n",
    "    elif round(row[\"aqiAvg\"],0) >= 101 and round(row[\"aqiAvg\"],0) < 151:\n",
    "        AQICategoryNumber = 3\n",
    "        AQICategory = \"Unhealthy for Sensitive Groups\"\n",
    "    elif round(row[\"aqiAvg\"],0) >= 151 and round(row[\"aqiAvg\"],0) < 201:\n",
    "        AQICategoryNumber = 4\n",
    "        AQICategory = \"Unhealthy\"\n",
    "    elif round(row[\"aqiAvg\"],0) >= 201 and round(row[\"aqiAvg\"],0) < 301:\n",
    "        AQICategoryNumber = 5\n",
    "        AQICategory = \"Very Unhealthy\"\n",
    "    elif round(row[\"aqiAvg\"],0) >= 301:\n",
    "        AQICategoryNumber = 6\n",
    "        AQICategory = \"Hazardous\"\n",
    "    return AQICategory\n",
    "\n",
    "# Visualize the DataFrame\n",
    "summaryApiData_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert & export summary DataFrame to CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "summaryApiData_df.to_csv(f\"{output_data_filepath}AirNowApiData_summary_{timestamp}.csv\", encoding=\"utf-8\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
